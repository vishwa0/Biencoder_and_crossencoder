{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bfu6K5NtHRyp"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "import gzip\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "i6d6xLDgIFBn"
   },
   "outputs": [],
   "source": [
    "# Read the data from a CSV file and select relevant columns\n",
    "df_queries = pd.read_csv('antique_queries.csv')\n",
    "df_queries = df_queries[['query_id','text']]\n",
    "\n",
    "df_docs = pd.read_csv('antique_data.csv')\n",
    "df_docs = df_docs[['doc_id','text']]\n",
    "\n",
    "df_qrel = pd.read_csv('antique_qrels.csv')\n",
    "df_qrel = df_qrel[['query_id','doc_id','relevence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wEA5GzQ_IE-L"
   },
   "outputs": [],
   "source": [
    "# Merge the relevance data with the document data based on doc_id\n",
    "merged_df = df_qrel.merge(df_docs, on='doc_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1964316</td>\n",
       "      <td>1964316_5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1964316</td>\n",
       "      <td>1674088_11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1964316</td>\n",
       "      <td>1218838_13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1964316</td>\n",
       "      <td>1519022_15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1964316</td>\n",
       "      <td>3059341_5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6584</th>\n",
       "      <td>1262692</td>\n",
       "      <td>247023_6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6585</th>\n",
       "      <td>1262692</td>\n",
       "      <td>1499030_5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6586</th>\n",
       "      <td>1262692</td>\n",
       "      <td>2916758_0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6587</th>\n",
       "      <td>1262692</td>\n",
       "      <td>1105845_15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6588</th>\n",
       "      <td>1262692</td>\n",
       "      <td>3699008_1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6589 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      query_id      doc_id  relevence  label\n",
       "0      1964316   1964316_5          4      1\n",
       "1      1964316  1674088_11          1      0\n",
       "2      1964316  1218838_13          2      0\n",
       "3      1964316  1519022_15          2      0\n",
       "4      1964316   3059341_5          2      0\n",
       "...        ...         ...        ...    ...\n",
       "6584   1262692    247023_6          3      1\n",
       "6585   1262692   1499030_5          3      1\n",
       "6586   1262692   2916758_0          3      1\n",
       "6587   1262692  1105845_15          3      1\n",
       "6588   1262692   3699008_1          2      0\n",
       "\n",
       "[6589 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_values(value):\n",
    "    if value in [3, 4]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "# Apply the mapping function to create binary labels and add to the relevance data\n",
    "df_qrel['label'] = df_qrel['relevence'].apply(map_values)\n",
    "\n",
    "# Drop duplicate entries based on query_id and doc_id in the relevance data\n",
    "df_qrel1 = df_qrel.drop_duplicates(subset=['query_id','doc_id'])\n",
    "df_qrel1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qrel1 = df_qrel1.merge(df_queries, on='query_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevence</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1964316</td>\n",
       "      <td>1964316_5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>What do you mean by \"weed\"?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1964316</td>\n",
       "      <td>1674088_11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>What do you mean by \"weed\"?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1964316</td>\n",
       "      <td>1218838_13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>What do you mean by \"weed\"?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1964316</td>\n",
       "      <td>1519022_15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>What do you mean by \"weed\"?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1964316</td>\n",
       "      <td>3059341_5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>What do you mean by \"weed\"?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id      doc_id  relevence  label                         text\n",
       "0   1964316   1964316_5          4      1  What do you mean by \"weed\"?\n",
       "1   1964316  1674088_11          1      0  What do you mean by \"weed\"?\n",
       "2   1964316  1218838_13          2      0  What do you mean by \"weed\"?\n",
       "3   1964316  1519022_15          2      0  What do you mean by \"weed\"?\n",
       "4   1964316   3059341_5          2      0  What do you mean by \"weed\"?"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qrel1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgV4qzX5IE7s",
    "outputId": "b6d536a4-d6be-41f3-94e1-07f0a5c68726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6589 entries, 0 to 6588\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   query_id   6589 non-null   int64 \n",
      " 1   doc_id     6589 non-null   object\n",
      " 2   relevence  6589 non-null   int64 \n",
      " 3   text       6589 non-null   object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 257.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display information about the merged DataFrame\n",
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "crSlW4oqIE5E"
   },
   "outputs": [],
   "source": [
    "# Extract the 'doc_id' and 'text' columns from the merged DataFrame\n",
    "df_text = merged_df[['doc_id','text']]\n",
    "\n",
    "# Initialize an empty list to store passages\n",
    "passages = []\n",
    "\n",
    "# Iterate through each row in the 'df_text' DataFrame and append text to the 'passages' list\n",
    "for index, row in df_text.iterrows():\n",
    "    passages.append(str(row['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxuEM0OVIE2n",
    "outputId": "489e4f08-e46e-45a5-8334-e2876842cd91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Weed could mean the bad thing that grow in ur graden or back and front yard. Or it could mean the drug.',\n",
       " 'sell weed',\n",
       " 'My weed!!',\n",
       " 'because we dont know what the hell to make legal in the US anymore....i mean we still have Bush in office, you would think that legalizing weed would be less harsh of the 2',\n",
       " 'Its a weed.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 passages\n",
    "passages[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fzpN5J-IE0R",
    "outputId": "4e149b42-30f5-47cb-9212-f10552ee5761"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('intfloat/e5-large-v2')\n",
    "embeddings = model.encode(passages,convert_to_tensor=True,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xaJ8USohIExv"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('corpus_embeddings_text.pickle', 'wb') as pkl:\n",
    "    pickle.dump(embeddings, pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HEH_psb3IEp8"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vqqfyX_2IEnp"
   },
   "outputs": [],
   "source": [
    "with open('corpus_embeddings_text.pickle', 'rb') as pkl:\n",
    "    doc_embedding = pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most relevant documents for query 1: [21  0  9  4  2  8 26  6 29 18]\n",
      "Corresponding similarity scores: [0.85521793 0.8483332  0.84732294 0.8440726  0.8430238  0.83978856\n",
      " 0.83952945 0.8394203  0.8377141  0.83636487]\n",
      "Most relevant documents for query 2: [21  0  9  4  2  8 26  6 29 18]\n",
      "Corresponding similarity scores: [0.85521793 0.8483332  0.84732294 0.8440726  0.8430238  0.83978856\n",
      " 0.83952945 0.8394203  0.8377141  0.83636487]\n",
      "Most relevant documents for query 3: [21  0  9  4  2  8 26  6 29 18]\n",
      "Corresponding similarity scores: [0.85521793 0.8483332  0.84732294 0.8440726  0.8430238  0.83978856\n",
      " 0.83952945 0.8394203  0.8377141  0.83636487]\n",
      "Most relevant documents for query 4: [21  0  9  4  2  8 26  6 29 18]\n",
      "Corresponding similarity scores: [0.85521793 0.8483332  0.84732294 0.8440726  0.8430238  0.83978856\n",
      " 0.83952945 0.8394203  0.8377141  0.83636487]\n",
      "Most relevant documents for query 5: [21  0  9  4  2  8 26  6 29 18]\n",
      "Corresponding similarity scores: [0.85521793 0.8483332  0.84732294 0.8440726  0.8430238  0.83978856\n",
      " 0.83952945 0.8394203  0.8377141  0.83636487]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def fetch_relevant_documents(query_embedding, document_embeddings, top_k=10):\n",
    "    # Calculate cosine similarity between the query embedding and document embeddings\n",
    "    similarities = cosine_similarity(query_embedding.reshape(1, -1), document_embeddings)[0]\n",
    "    \n",
    "    # Sort document indices based on similarity scores (higher is better)\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    \n",
    "    # Get the top-k most relevant document indices and their similarity scores\n",
    "    top_indices = sorted_indices[:top_k]\n",
    "    top_similarity_scores = similarities[top_indices]\n",
    "    \n",
    "    return top_indices, top_similarity_scores\n",
    "\n",
    "# Load embeddings from pickle files\n",
    "\n",
    "for i in range(5):\n",
    "    query_embed = model.encode(df_qrel1['text'][i],convert_to_tensor=True)\n",
    "    relevant_document_indices, similarity_scores = fetch_relevant_documents(query_embed, doc_embedding)\n",
    "\n",
    "    print(f\"Most relevant documents for query {i+1}:\", relevant_document_indices)\n",
    "    print(\"Corresponding similarity scores:\", similarity_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_documents(query_embedding, document_embeddings, top_k=170):\n",
    "    # Calculate cosine similarity between the query embedding and document embeddings\n",
    "    similarities = cosine_similarity(query_embedding.reshape(1, -1), document_embeddings)[0]\n",
    "    \n",
    "    # Sort document indices based on similarity scores (higher is better)\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    \n",
    "    # Get the top-k most relevant document indices and their similarity scores\n",
    "    top_indices = sorted_indices[:top_k]\n",
    "    \n",
    "    return top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ids = df_qrel1['doc_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall: 0.9075540009933921\n"
     ]
    }
   ],
   "source": [
    "# Calculate recall for each query\n",
    "def calculate_recall(query_id, qrel_df):\n",
    "    relevant_documents = df_qrel1[(df_qrel1['query_id'] == query_ids[i]) & (df_qrel1['label'] == 1)]['doc_id'].tolist()\n",
    "    #print(relevant_documents)\n",
    "    query = df_qrel1[df_qrel1['query_id'] == query_ids[i]]['text'].iloc[0]\n",
    "    #print(query)\n",
    "    query_embed = model.encode(query,convert_to_tensor=True)\n",
    "    retrieved_index = fetch_documents(query_embed, doc_embedding) \n",
    "    retrieved_doc_ids = [doc_ids[i] for i in retrieved_index]\n",
    "    #print(retrieved_doc_ids)\n",
    "    retrieved_relevant_documents = list(set(relevant_documents) & set(retrieved_doc_ids))\n",
    "    #print(retrieved_relevant_documents)\n",
    "    try:\n",
    "        recall = len(retrieved_relevant_documents) / len(relevant_documents)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0.0  \n",
    "    return recall\n",
    "\n",
    "# List of unique query IDs\n",
    "query_ids = df_qrel1['query_id'].unique()\n",
    "\n",
    "total_recall = 0\n",
    "\n",
    "for i in range(len(query_ids)):\n",
    "    recall = calculate_recall(query_ids[i], df_qrel1)\n",
    "    total_recall += recall\n",
    "\n",
    "average_recall = total_recall / len(query_ids)\n",
    "print(\"Average Recall:\", average_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrttLHL4IElH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
